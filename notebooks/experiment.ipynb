{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspace')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import rootutils\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from loguru import logger\n",
    "\n",
    "rootutils.setup_root(\".\", cwd=True, dotenv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_QUERY = {\n",
    "    \"query\": \"光格子時計\",\n",
    "    \"lang\": \"ja\",\n",
    "}\n",
    "CHUNK_SIZE = 1024\n",
    "CHUNK_OVERLAP = 24\n",
    "MAX_DOCUMENTS = 1\n",
    "\n",
    "LLM = VertexAI(model_name=\"gemini-1.5-flash-001\", temperature=0, max_output_tokens=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wikipedia_documents(\n",
    "    query: str,\n",
    "    lang: str,\n",
    "    cache_dir: str | Path = \"data/cache/wikipedia\",\n",
    "    **kwargs,\n",
    ") -> list[Document]:\n",
    "    \"\"\"Downloads Wikipedia documents based on the given query and language\"\"\"\n",
    "    cache_dir = Path(cache_dir)\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cache_filepath = cache_dir / f\"{query}_{lang}.pkl\"\n",
    "    if cache_filepath.exists():\n",
    "        logger.info(f\"Loading cached Wikipedia documents from {cache_filepath}\")\n",
    "        return joblib.load(cache_filepath)\n",
    "\n",
    "    logger.info(f\"Downloading Wikipedia documents for query '{query}' in language '{lang}'\")\n",
    "    loader = WikipediaLoader(query=query, lang=lang, **kwargs)\n",
    "    documents = loader.load()\n",
    "    joblib.dump(documents, cache_filepath)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-15 19:46:13.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mdownload_wikipedia_documents\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mLoading cached Wikipedia documents from data/cache/wikipedia/光格子時計_ja.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "raw_documents = download_wikipedia_documents(**WIKI_QUERY)\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")  # どのモデルでも gpt-2 の tokenizer を使用する\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents[:MAX_DOCUMENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=LLM,\n",
    "    allowed_nodes=[\n",
    "        \"PERSON\",\n",
    "        \"ORGANIZATION\",\n",
    "        \"LOCATION\",\n",
    "        \"OBJECT\",\n",
    "        \"EVENT\",\n",
    "        \"DATE\",\n",
    "        \"MONEY\",\n",
    "        \"QUANTITY\",\n",
    "        \"USAGE\",\n",
    "        \"INVENTION\",\n",
    "        \"THEORY\",\n",
    "    ],\n",
    "    allowed_relationships=None,  # TODO: ここに関係を指定する\n",
    ")\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store to neo4j\n",
    "graph = Neo4jGraph()\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=True, include_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete all nodes\n",
    "# graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
