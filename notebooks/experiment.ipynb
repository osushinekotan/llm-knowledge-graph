{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import rootutils\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from loguru import logger\n",
    "\n",
    "rootutils.setup_root(\".\", cwd=True, dotenv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_QUERY = {\n",
    "    \"query\": \"光格子時計\",\n",
    "    \"lang\": \"ja\",\n",
    "}\n",
    "CHUNK_SIZE = 3072\n",
    "CHUNK_OVERLAP = 24\n",
    "MAX_DOCUMENTS = 1\n",
    "\n",
    "LLM = VertexAI(model_name=\"gemini-1.5-flash-001\", temperature=0, max_output_tokens=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wikipedia_documents(\n",
    "    query: str,\n",
    "    lang: str,\n",
    "    cache_dir: str | Path = \"data/cache/wikipedia\",\n",
    "    **kwargs,\n",
    ") -> list[Document]:\n",
    "    \"\"\"Downloads Wikipedia documents based on the given query and language\"\"\"\n",
    "    cache_dir = Path(cache_dir)\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cache_filepath = cache_dir / f\"{query}_{lang}.pkl\"\n",
    "    if cache_filepath.exists():\n",
    "        logger.info(f\"Loading cached Wikipedia documents from {cache_filepath}\")\n",
    "        return joblib.load(cache_filepath)\n",
    "\n",
    "    logger.info(f\"Downloading Wikipedia documents for query '{query}' in language '{lang}'\")\n",
    "    loader = WikipediaLoader(query=query, lang=lang, **kwargs)\n",
    "    documents = loader.load()\n",
    "    joblib.dump(documents, cache_filepath)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = download_wikipedia_documents(**WIKI_QUERY)\n",
    "\n",
    "# metadata title で query を一番上に\n",
    "raw_documents = sorted(raw_documents, key=lambda x: x.metadata[\"title\"] != WIKI_QUERY[\"query\"])\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")  # どのモデルでも gpt-2 の tokenizer を使用する\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents[:MAX_DOCUMENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=LLM,\n",
    "    allowed_nodes=[\n",
    "        \"人物\",\n",
    "        \"組織\",\n",
    "        \"場所\",\n",
    "        \"物体\",\n",
    "        \"出来事\",\n",
    "        \"日付\",\n",
    "        \"お金\",\n",
    "        \"数量\",\n",
    "        \"使用\",\n",
    "        \"発明\",\n",
    "        \"理論\",\n",
    "        \"方法\",\n",
    "        \"材料\",\n",
    "        \"概念\",\n",
    "        \"行動\",\n",
    "        \"状態\",\n",
    "        \"数値\",\n",
    "        \"時間\",\n",
    "    ],\n",
    "    allowed_relationships=[\n",
    "        \"測定する\",\n",
    "        \"使用する\",\n",
    "        \"検出する\",\n",
    "        \"必要とする\",\n",
    "        \"含む\",\n",
    "        \"生産する\",\n",
    "        \"維持する\",\n",
    "        \"校正する\",\n",
    "        \"接続する\",\n",
    "        \"サポートする\",\n",
    "        \"改善する\",\n",
    "        \"安定化する\",\n",
    "        \"同期する\",\n",
    "        \"生成する\",\n",
    "        \"転送する\",\n",
    "        \"操作する\",\n",
    "        \"調整する\",\n",
    "        \"定義する\",\n",
    "        \"検証する\",\n",
    "        \"強化する\",\n",
    "        \"規制する\",\n",
    "        \"制御する\",\n",
    "        \"分析する\",\n",
    "        \"最適化する\",\n",
    "        \"通信する\",\n",
    "        \"内包する\",\n",
    "        \"構成する\",\n",
    "        \"発明する\",\n",
    "    ],\n",
    ")\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store to neo4j\n",
    "graph = Neo4jGraph()\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=True, include_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all nodes\n",
    "# graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
